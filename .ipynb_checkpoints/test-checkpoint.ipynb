{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc842d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch._C import unify_type_list\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.autograd as autograd         # computation graph\n",
    "import numpy as np\n",
    "from pyDOE import lhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2635bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNBTPDENN(nn.Module):\n",
    "    def __init__(self,layerslist):\n",
    "        super(PINNBTPDENN, self).__init__()\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "\n",
    "        self.diffusivity = 2e-3\n",
    "        self.bvalue = 500\n",
    "\n",
    "        # self.flatten = nn.Flatten()\n",
    "        modules = []\n",
    "        for i in range(0,len(layerslist)-1):\n",
    "            nnlayer = nn.Linear(layerslist[i], layerslist[i+1]).to(torch.cfloat)\n",
    "            nn.init.xavier_normal_(nnlayer.weight.data)\n",
    "            nn.init.zeros_(nnlayer.bias.data)\n",
    "            modules.append(nnlayer)\n",
    "            if i != len(layerslist)-2:\n",
    "                modules.append(nn.Tanh())\n",
    "\n",
    "        self.layers = nn.Sequential(*modules)\n",
    "        # alternative choice is nn.init.normal_ or nn.init.kaiming_uniform_ kaiming_normal_\n",
    "\n",
    "        self.iter = 0\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X is stack of x and t\n",
    "        if torch.is_tensor(X) != True:         \n",
    "            X = torch.from_numpy(X)\n",
    "\n",
    "        H = self.layers(X.cfloat())\n",
    "        return H\n",
    "    \n",
    "    def compute_u_1order(self, x):\n",
    "        self.u_x = torch.autograd.functional.jacobian(self, x, create_graph=True)\n",
    "        self.u_x = torch.squeeze(self.u_x)\n",
    "        return self.u_x\n",
    "    \n",
    "    def compute_u_2order(self, x):\n",
    "        self.u_xx = torch.autograd.functional.jacobian(self.compute_u_1order, x)\n",
    "        self.u_xx = torch.squeeze(self.u_xx)\n",
    "        return self.u_xx\n",
    "    \n",
    "    def loss_PDE(self, x,y):\n",
    "                \n",
    "        # x_1_f = x_to_train_f[:,[0]]\n",
    "        # x_2_f = x_to_train_f[:,[1]]\n",
    "                        \n",
    "        g = x.clone()\n",
    "                        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        u = self.forward(g)\n",
    "                \n",
    "#         u_1order = autograd.grad(u,g,torch.ones([x.shape[0], 1]).cfloat().to(device), retain_graph=True, create_graph=True)  \n",
    "# #         u_2order = autograd.grad(u_1order,g,torch.ones(x.shape).cfloat().to(device), create_graph=True)[0]\n",
    "#         u_2order = [0,0]\n",
    "\n",
    "        u_1order = self.compute_u_1order(g)\n",
    "        u_2order = self.compute_u_2order(g)\n",
    "        \n",
    "                \n",
    "        return u_1order, u_2order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1846a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnlayers = [4, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PINNBTPDENN(nnlayers).to(device)\n",
    "radius = 1\n",
    "demiheight = 50\n",
    "N_f_train = 5\n",
    "lb = np.array([-radius,-radius,-demiheight,0])\n",
    "ub = np.array([radius,radius,demiheight,15000])\n",
    "Input_f_train = lb + (ub-lb)*lhs(4,N_f_train) \n",
    "Input_f_train = torch.from_numpy(Input_f_train).float().to(device)\n",
    "zero_f_train = torch.zeros(Input_f_train.shape[0],1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e870cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 4.2046e-16, -2.8412e-15,  3.6925e-16,  9.4617e-17],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "u_1order, u_2order = model.loss_PDE(Input_f_train,zero_f_train)\n",
    "print(Input_f_train.size())\n",
    "print(u_1order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed50b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defaut",
   "language": "python",
   "name": "defaut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
